name: CreateCluster
description: 'Installs Go Downloads and installs Karpenter Dependencies'
inputs:
  account_id:
    description: "Account ID to access AWS"
    required: true
  role:
    description: "Role to access AWS"
    required: true
  region:
    description: "Region to access AWS"
    required: true
  cluster_name:
    description: 'Name of the cluster to be launched by eksctl'
    required: true
  k8s_version:
    description: 'Version of Kubernetes to use for the launched cluster'
    required: false
    default: "1.27"
  ip_family:
    description: "IP Family of the cluster. Valid values are IPv4 or IPv6"
    required: false
    default: "IPv4"
  git_ref:
    description: "The git commit, tag, or branch to check out. Requires a corresponding Karpenter snapshot release"
    required: false
runs:
  using: "composite"
  steps:
  - name: configure aws credentials
    uses: aws-actions/configure-aws-credentials@v4
    with:
      role-to-assume: arn:aws:iam::${{ inputs.account_id }}:role/${{ inputs.role }}
      aws-region: ${{ inputs.region }}
      role-duration-seconds: 21600
  - uses: actions/checkout@v4
    with:
      ref: ${{ inputs.git_ref }}
  - uses: ./.github/actions/e2e/install-eksctl
    with:
      eksctl_version: v0.147.0
  - name: create iam policies
    shell: bash
    run: |
      # Resolve the cloudformation path with fallback
      CLOUDFORMATION_PATH=website/content/en/preview/getting-started/getting-started-with-karpenter/cloudformation.yaml
      if [ ! -f $CLOUDFORMATION_PATH ]; then
        CLOUDFORMATION_PATH=website/content/en/preview/getting-started/getting-started-with-eksctl/cloudformation.yaml
      fi
      
      # Update the Cloudformation policy to add the permissionBoundary to the NodeRole
      yq -i '.Resources.KarpenterNodeRole.Properties.PermissionsBoundary="arn:aws:iam::${{ inputs.account_id }}:policy/GithubActionsPermissionsBoundary"' $CLOUDFORMATION_PATH
      
      aws iam create-service-linked-role --aws-service-name spot.amazonaws.com || true
      aws cloudformation deploy \
        --stack-name iam-${{ inputs.cluster_name }} \
        --template-file $CLOUDFORMATION_PATH \
        --capabilities CAPABILITY_NAMED_IAM \
        --parameter-overrides "ClusterName=${{ inputs.cluster_name }}" \
        --tags "testing/type=e2e" "github.com/run-url=https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}" "karpenter.sh/discovery=${{ inputs.cluster_name }}"
  - name: create or upgrade cluster
    shell: bash
    run: |
      # Create or Upgrade the cluster based on whether the cluster already exists
      cmd="create"
      eksctl get cluster --name ${{ inputs.cluster_name }} && cmd="upgrade"
      
      eksctl ${cmd} cluster -f - <<EOF
      ---
      apiVersion: eksctl.io/v1alpha5
      kind: ClusterConfig
      metadata:
        name: ${{ inputs.cluster_name }}
        region: ${{ inputs.region }}
        version: "${{ inputs.k8s_version }}"
        tags:
          karpenter.sh/discovery: ${{ inputs.cluster_name }}
          github.com/run-url: "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          testing/type: "e2e"
      kubernetesNetworkConfig:
        ipFamily: ${{ inputs.ip_family }}
      managedNodeGroups:
        - instanceType: c5.4xlarge
          amiFamily: AmazonLinux2
          name: ${{ inputs.cluster_name }}-system-pool
          desiredCapacity: 2
          disableIMDSv1: true
          minSize: 2
          maxSize: 2
          iam:
            instanceRolePermissionsBoundary: "arn:aws:iam::${{ inputs.account_id }}:policy/GithubActionsPermissionsBoundary"
          taints:
          - key: CriticalAddonsOnly
            value: "true"
            effect: NoSchedule
      iam:
        serviceRolePermissionsBoundary: "arn:aws:iam::${{ inputs.account_id }}:policy/GithubActionsPermissionsBoundary"
        serviceAccounts:
          - metadata:
              name: karpenter
              namespace: karpenter
            attachPolicyARNs:
              - "arn:aws:iam::${{ inputs.account_id }}:policy/KarpenterControllerPolicy-${{ inputs.cluster_name }}"
            permissionsBoundary: "arn:aws:iam::${{ inputs.account_id }}:policy/GithubActionsPermissionsBoundary"
            roleName: karpenter-irsa-${{ inputs.cluster_name }}
            roleOnly: true
          - metadata:
              name: prometheus-kube-prometheus-prometheus
              namespace: prometheus
            attachPolicyARNs:
              - "arn:aws:iam::${{ inputs.account_id }}:policy/PrometheusWorkspaceIngestionPolicy"
            permissionsBoundary: "arn:aws:iam::${{ inputs.account_id }}:policy/GithubActionsPermissionsBoundary"
            roleName: prometheus-irsa-${{ inputs.cluster_name }}
            roleOnly: true
        withOIDC: true
      addons:
      - name: vpc-cni
        permissionsBoundary: "arn:aws:iam::${{ inputs.account_id }}:policy/GithubActionsPermissionsBoundary"
      - name: coredns
        permissionsBoundary: "arn:aws:iam::${{ inputs.account_id }}:policy/GithubActionsPermissionsBoundary"
      - name: kube-proxy
        permissionsBoundary: "arn:aws:iam::${{ inputs.account_id }}:policy/GithubActionsPermissionsBoundary"
      - name: aws-ebs-csi-driver
        permissionsBoundary: "arn:aws:iam::${{ inputs.account_id }}:policy/GithubActionsPermissionsBoundary"
        wellKnownPolicies:
          ebsCSIController: true
      EOF
  - name: tag oidc provider of the cluster
    if: always()
    shell: bash
    run: |
      oidc_id=$(aws eks describe-cluster --name ${{ inputs.cluster_name }} --query "cluster.identity.oidc.issuer" --output text | cut -d '/' -f 3,4,5)
      arn="arn:aws:iam::${{ inputs.account_id }}:oidc-provider/${oidc_id}"
      aws iam tag-open-id-connect-provider --open-id-connect-provider-arn $arn \
         --tags Key=testing/type,Value=e2e  Key=github.com/run-url,Value=https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}
  - name: give KarpenterNodeRole permission to bootstrap
    shell: bash
    run: |
      eksctl create iamidentitymapping \
      --username system:node:{{EC2PrivateDNSName}} \
      --cluster "${{ inputs.cluster_name }}" \
      --arn "arn:aws:iam::${{ inputs.account_id }}:role/KarpenterNodeRole-${{ inputs.cluster_name }}" \
      --group system:bootstrappers \
      --group system:nodes
  - name: cloudformation describe stack events
    shell: bash
    if: failure()
    run: |
      stack_names=$(aws cloudformation describe-stacks --query 'Stacks[?Tags[?Key == `karpenter.sh/discovery` && Value == `${{ inputs.CLUSTER_NAME }}`]].{StackName: StackName}' --output text)
      for stack_name in $stack_names; do
        echo "Stack Events for $stack_name:"
        aws cloudformation describe-stack-events --stack-name $stack_name
      done